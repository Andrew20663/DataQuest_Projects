{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guided Project: Building a Spam Filter with Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exploring the Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this particular project, I will create a Spam Filter with the Naive Bayes algorithm (Multinomial Naive Bayes) by classifying messages as spam or non-spam. In order to achieve this, the computer must be able to do three steps: \n",
    "\n",
    "   1) Learn how people classify messages. \n",
    "   \n",
    "   2) Calculate probabilites for a new message either being spam or non-spam.\n",
    "   \n",
    "   3) Classify the respective message by seeing which probability value is \n",
    "      higher. For example, if spam is greater than non-spam with respect to\n",
    "      probabilites, then the message is spam. \n",
    "      \n",
    "So, I will proceed with the first step by teaching the computer how to classify messages. The dataset that I'll be using is a dataset from the UCI Machine Learning Repository. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5572 rows and 2 columns in this dataset\n",
      "There are 4825 non-spam messages and 747 spam messages\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ham     0.865937\n",
       "spam    0.134063\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv('SMSSpamCollection', sep = '\\t', parse_dates = True, header = None, names = ['Label', 'SMS'])\n",
    "print('There are {} rows and {} columns in this dataset'.format(df.shape[0], df.shape[1]))\n",
    "df.head()\n",
    "df['Label'].value_counts()\n",
    "df['Label'].value_counts(normalize = True) * 100\n",
    "print('There are {} non-spam messages and {} spam messages'.format(df['Label'].value_counts()[0], df['Label'].value_counts()[1]))\n",
    "df['Label'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After analyzing the data, I will now move to the next step which is to build the spam filter. From the data, I saw that there are 5,572 rows and 2 columns in this dataset. Also, I then saw that there are 4,825 non-spam messages and 747 spam messages. In order to test the validity of the spam filter, I will divide the dataset into two categories\n",
    "    \n",
    "   1) Training Set: Set we will use to 'train' the computer on how to classify\n",
    "      these messages. \n",
    "    \n",
    "   2) Test Set: Set we will use to test how good the spam filter is on \n",
    "      classifying new messages.\n",
    "\n",
    "I will split the dataset 80% training and 20% testing. Therefore, the training set will have 4,458 messages and then the test set will have 1,114 messages. The 1,114 messages will be the messages already classified by a human and then the spam filter will treat them as new and try to classify them. I will create a training and test set by randomizing the dataset. \n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham     3858\n",
      "spam     600\n",
      "Name: Label, dtype: int64\n",
      "\n",
      "\n",
      "ham     0.86541\n",
      "spam    0.13459\n",
      "Name: Label, dtype: float64\n",
      "\n",
      "\n",
      "ham     967\n",
      "spam    147\n",
      "Name: Label, dtype: int64\n",
      "\n",
      "\n",
      "ham     0.868043\n",
      "spam    0.131957\n",
      "Name: Label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "randomized_data = df.sample(frac = 1, random_state = 1) \n",
    "training_test_index = round(len(randomized_data) * 0.8)\n",
    "training_set = randomized_data[:training_test_index].reset_index(drop = True)\n",
    "test_set = randomized_data[training_test_index:].reset_index(drop = True)\n",
    "print(training_set['Label'].value_counts())\n",
    "print('\\n')\n",
    "print(training_set['Label'].value_counts(normalize = True))\n",
    "print('\\n')\n",
    "print(test_set['Label'].value_counts())\n",
    "print('\\n')\n",
    "print(test_set['Label'].value_counts(normalize = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Letter Case and Punctuation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous step, I split the data into a training and test set. Now, I will use the training set to teach the algorithm to classify new messages. I now need to calculate the probabilites that are needed: \n",
    "\n",
    "   1) P(Spam | message) \n",
    "   \n",
    "   2) P(Ham | message) \n",
    "\n",
    "To calculate these probabilites, I will need to clean the data so that the format will allow us to extract the information I need very easily. I will replace the SMS column with a new columns where each column represents a unique word from the vocabulary. Also, each row represents a single message, all words are lower case, and punctuation is not taken into account anymore. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                         yep  by the pretty sculpture\n",
       "1        yes  princess  are you going to make me moan \n",
       "2                           welp apparently he retired\n",
       "3                                              havent \n",
       "4    i forgot 2 ask ü all smth   there s a card on ...\n",
       "Name: SMS, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set['SMS'] = training_set['SMS'].str.replace('\\W', ' ').str.lower()\n",
    "training_set['SMS'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous step I removed the punctuation and changed all letters to lowercase. Everything except the 'Label' column will be transformed in which there will be a unique word in our vocabulary. I will now create the unique words that occur in the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7783"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set['SMS'] = training_set['SMS'].str.split()\n",
    "vocabulary = []\n",
    "for n in training_set['SMS']:\n",
    "    for word in n: \n",
    "        vocabulary.append(word)\n",
    "\n",
    "vocabulary = list(set(vocabulary))\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Training Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating the vocabulary for the messages in the training set, I will now make the data transformation from the vocabulary. The finished product will be a new dataframe, but before I can achieve this, I will need to build a dictionary that will convert to a dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>0</th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000pes</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>02</th>\n",
       "      <th>...</th>\n",
       "      <th>zindgi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zogtorius</th>\n",
       "      <th>zouk</th>\n",
       "      <th>zyada</th>\n",
       "      <th>é</th>\n",
       "      <th>ú1</th>\n",
       "      <th>ü</th>\n",
       "      <th>〨ud</th>\n",
       "      <th>鈥</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  0  00  000  \\\n",
       "0   ham                  [yep, by, the, pretty, sculpture]  0   0    0   \n",
       "1   ham  [yes, princess, are, you, going, to, make, me,...  0   0    0   \n",
       "2   ham                    [welp, apparently, he, retired]  0   0    0   \n",
       "3   ham                                           [havent]  0   0    0   \n",
       "4   ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,...  0   0    0   \n",
       "\n",
       "   000pes  008704050406  0089  01223585334  02 ...  zindgi  zoe  zogtorius  \\\n",
       "0       0             0     0            0   0 ...       0    0          0   \n",
       "1       0             0     0            0   0 ...       0    0          0   \n",
       "2       0             0     0            0   0 ...       0    0          0   \n",
       "3       0             0     0            0   0 ...       0    0          0   \n",
       "4       0             0     0            0   0 ...       0    0          0   \n",
       "\n",
       "   zouk  zyada  é  ú1  ü  〨ud  鈥  \n",
       "0     0      0  0   0  0    0  0  \n",
       "1     0      0  0   0  0    0  0  \n",
       "2     0      0  0   0  0    0  0  \n",
       "3     0      0  0   0  0    0  0  \n",
       "4     0      0  0   0  2    0  0  \n",
       "\n",
       "[5 rows x 7785 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts_per_sms = {unique_word: [0] * len(training_set['SMS']) for unique_word in vocabulary}\n",
    "\n",
    "for index, sms in enumerate(training_set['SMS']):\n",
    "    for word in sms:\n",
    "        word_counts_per_sms[word][index] += 1\n",
    "\n",
    "word_counts_per_sms = pd.DataFrame(word_counts_per_sms)\n",
    "training_set_clean = pd.concat([training_set, word_counts_per_sms], axis = 1)\n",
    "training_set_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Constants First"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After finishing the data cleaning and creating the data, I finally have a training set that I can work with. I will begin creating the spam filter at this point by following the multinomial Naive Bayes Algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spam = training_set_clean[training_set_clean['Label'] == 'spam']\n",
    "ham = training_set_clean[training_set_clean['Label'] == 'ham']\n",
    "\n",
    "p_spam = len(spam) / len(training_set_clean)\n",
    "p_ham = len(ham) / len(training_set_clean) \n",
    "\n",
    "number_of_spam_words = spam['SMS'].apply(len)\n",
    "n_spam = number_of_spam_words.sum()\n",
    "\n",
    "number_of_ham_words = ham['SMS'].apply(len)\n",
    "n_ham = number_of_ham_words.sum()\n",
    "\n",
    "number_of_vocabulary = len(vocabulary)\n",
    "\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous step, I calculated the constants needed for the equation. Now, I need to calculate the parameters, the probability of a word given non-spam and the probability of a word given spam. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spam_parameters = {unique_word : 0 for unique_word in vocabulary}\n",
    "ham_parameters = {unique_word : 0 for unique_word in vocabulary}\n",
    "\n",
    "for word in vocabulary: \n",
    "    number_of_words_given_spam = spam[word].sum()\n",
    "    prob_word_given_spam = (number_of_words_given_spam + alpha) / (n_spam + (alpha * number_of_vocabulary))\n",
    "    spam_parameters[word] = prob_word_given_spam\n",
    "    \n",
    "    number_of_words_given_ham = ham[word].sum()\n",
    "    prob_word_given_ham = (number_of_words_given_ham + alpha) / (n_ham + (alpha * number_of_vocabulary))\n",
    "    ham_parameters[word] = prob_word_given_ham"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying A New Message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After calculating the constants and calculating the parameters I needed, I can start to make the spam filter. The spam filter is a function that: \n",
    "    \n",
    "   1) Takes in input to be the message.\n",
    "   \n",
    "   2) Calculates P(Spam | w1, w2, .., wn) and P(Ham | w1, w2, .., wn) \n",
    "   \n",
    "   3) Compares which of the two are greater and the bigger one gets assigned the \n",
    "      title of either spam or not spam. \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def classify(message):\n",
    "\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "\n",
    "\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "    \n",
    "    for word in message: \n",
    "        if word in spam_parameters: \n",
    "            p_spam_given_message *= spam_parameters[word]\n",
    "        if word in ham_parameters: \n",
    "            p_ham_given_message *= ham_parameters[word]\n",
    "    \n",
    "\n",
    "    print('P(Spam|message):', p_spam_given_message)\n",
    "    print('P(Ham|message):', p_ham_given_message)\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        print('Label: Ham')\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        print('Label: Spam')\n",
    "    else:\n",
    "        print('Equal proabilities, have a human classify this!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 1.3481290211300841e-25\n",
      "P(Ham|message): 1.9368049028589875e-27\n",
      "Label: Spam\n",
      "\n",
      "\n",
      "P(Spam|message): 2.4372375665888117e-25\n",
      "P(Ham|message): 3.687530435009238e-21\n",
      "Label: Ham\n"
     ]
    }
   ],
   "source": [
    "classify('Winner!! This is the secret code to unlock the money: C3421.')\n",
    "print('\\n')\n",
    "classify(\"Sounds good, Tom, then see u there\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring the Spam Filter's Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result of our calculations for P(Spam|message) and P(Ham|message) for both calculations, I will now measure the accuracy of the filter on the test set of 1,114 messages. The algorithm will present a result with a classification label for every message in the new test set of 1,114 messages to compare with the actual label given by a human. I will calculate the accuracy of the algorithm and have accuracy defined as:\n",
    "       \n",
    "      - Accuracy = # correctly classified / total number classified messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_test_set(message):\n",
    "\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "\n",
    "\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "    \n",
    "    for word in message: \n",
    "        if word in spam_parameters: \n",
    "            p_spam_given_message *= spam_parameters[word]\n",
    "        if word in ham_parameters: \n",
    "            p_ham_given_message *= ham_parameters[word]\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'Ham'\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        return 'Spam'\n",
    "    else:\n",
    "        return 'Needs human classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Later i guess. I needa do mcat study too.</td>\n",
       "      <td>Ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>But i haf enuff space got like 4 mb...</td>\n",
       "      <td>Ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Oran...</td>\n",
       "      <td>Spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>All sounds good. Fingers . Makes it difficult ...</td>\n",
       "      <td>Ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>All done, all handed in. Don't know if mega sh...</td>\n",
       "      <td>Ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS predicted\n",
       "0   ham          Later i guess. I needa do mcat study too.       Ham\n",
       "1   ham             But i haf enuff space got like 4 mb...       Ham\n",
       "2  spam  Had your mobile 10 mths? Update to latest Oran...      Spam\n",
       "3   ham  All sounds good. Fingers . Makes it difficult ...       Ham\n",
       "4   ham  All done, all handed in. Don't know if mega sh...       Ham"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set['predicted'] = test_set['SMS'].apply(classify_test_set)\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham     967\n",
      "spam    147\n",
      "Name: Label, dtype: int64\n",
      "\n",
      "\n",
      "Ham                           969\n",
      "Spam                          144\n",
      "Needs human classification      1\n",
      "Name: predicted, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(test_set['Label'].value_counts())\n",
    "print('\\n')\n",
    "print(test_set['predicted'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, I managed to build a spam flter for SMS messages using the multinomial Naive Bayes algorithm. The project deemed to be successful with only 2 differences for ham, 3 differences for spam, and 1 human classification for the test_set vs. the predicted. The predicted guessed 2 more for the ham and 3 less for the spam. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
